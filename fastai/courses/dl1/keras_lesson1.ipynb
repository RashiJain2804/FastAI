{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to our first task: 'Dogs vs Cats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jainrashi2804/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9144428792294901886\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11310504346\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 17144102974020921219\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/dogscats/\"\n",
    "sz=224\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jainrashi2804/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'{PATH}train'\n",
    "validation_data_dir = f'{PATH}valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, #preprocess_input: zero-centers our image data using the mean channel values from the training dataset. This is an extremely important step that, if skipped, will cause all the predicted probabilities to be incorrect. This mean centering is whatâ€™s called data normalization, a fundamental concept in machine learning.\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "    target_size=(sz, sz),\n",
    "    batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(sz, sz),\n",
    "    batch_size=batch_size, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False) #include_top: whether to include the fully-connected layer at the top of the network.\n",
    "x = base_model.output                                        #example for include_top:  input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be  (299, 299, 3). It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g.  (150, 150, 3) would be one valid value.\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers: layer.trainable = False       #You can pass a trainable argument (boolean) to a layer constructor to set a layer to be non-trainable:\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "359/359 [==============================] - 210s 584ms/step - loss: 0.2174 - acc: 0.9464 - val_loss: 0.1006 - val_acc: 0.9768\n",
      "Epoch 2/3\n",
      "359/359 [==============================] - 207s 576ms/step - loss: 0.0862 - acc: 0.9711 - val_loss: 0.0878 - val_acc: 0.9768\n",
      "Epoch 3/3\n",
      "359/359 [==============================] - 207s 576ms/step - loss: 0.0692 - acc: 0.9758 - val_loss: 0.0683 - val_acc: 0.9830\n",
      "CPU times: user 14min 56s, sys: 49.4 s, total: 15min 45s\n",
      "Wall time: 10min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3244ad7940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#workers: maximum number of processes to spin up when using process based threading\n",
    "model.fit_generator(train_generator, train_generator.n // batch_size, epochs=3, workers = 4,validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at = 140\n",
    "for layer in model.layers[:split_at]: layer.trainable = False\n",
    "for layer in model.layers[split_at:]: layer.trainable = True\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "359/359 [==============================] - 253s 706ms/step - loss: 0.0798 - acc: 0.9729 - val_loss: 7.7805 - val_acc: 0.5096\n",
      "CPU times: user 5min 59s, sys: 24.5 s, total: 6min 24s\n",
      "Wall time: 4min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3246766d68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(train_generator, train_generator.n // batch_size, epochs=1, workers=3,\n",
    "        validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/135ebf9ccb113b1af214bc2b3ed1c20e"
  },
  "gist": {
   "data": {
    "description": "keras_lesson1",
    "public": true
   },
   "id": "135ebf9ccb113b1af214bc2b3ed1c20e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
